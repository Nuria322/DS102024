{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Scraping\n",
    "\n",
    "Descargar letras de canciones\n",
    "\n",
    "Utilizando beautiful soup descargar todas las canciones de [Lasso](https://es.wikipedia.org/wiki/Lasso_(cantante)) que hay en [letras.com](https://www.letras.com/lasso/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "letras_url = \"https://www.letras.com\"\n",
    "\n",
    "def descargar_letras(artista):\n",
    "    # COMPLETAR\n",
    "    return\n",
    "        \n",
    "artista = \"lasso\"\n",
    "descargar_letras(artista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron canciones. Verifica la clase utilizada.\n",
      "El DataFrame está vacío. Verifica los elementos en la página.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def descargar_letras(artista):\n",
    "    # Formar la URL del artista\n",
    "    url_artista = f\"https://www.letras.com/{artista}/\"\n",
    "    \n",
    "    # Realizamos la solicitud GET para obtener el contenido de la página del artista\n",
    "    response = requests.get(url_artista)\n",
    "    \n",
    "    # Comprobar que la solicitud fue exitosa\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error al acceder a la página de {artista}.\")\n",
    "        return pd.DataFrame()  # Retornar un DataFrame vacío en caso de error\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Inicializamos listas para los títulos y letras\n",
    "    titulos = []\n",
    "    letras = []\n",
    "\n",
    "    # Buscamos todos los contenedores de las canciones\n",
    "    canciones = soup.find_all('div', class_='titulo')  # Clase donde se encuentran los títulos de las canciones\n",
    "\n",
    "    if not canciones:\n",
    "        print(\"No se encontraron canciones. Verifica la clase utilizada.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for cancion in canciones:\n",
    "        # Extraemos el título de la canción\n",
    "        titulo_element = cancion.find('a')\n",
    "        if titulo_element:\n",
    "            titulos.append(titulo_element.text.strip())\n",
    "            letra_url = titulo_element['href']  # Obtener el enlace a la letra\n",
    "\n",
    "            # Realizar la solicitud GET para obtener la letra\n",
    "            letra_response = requests.get(letra_url)\n",
    "            if letra_response.status_code == 200:\n",
    "                letra_soup = BeautifulSoup(letra_response.text, \"html.parser\")\n",
    "                letra_div = letra_soup.find('div', class_='letra')  # Clase donde se encuentra la letra\n",
    "                if letra_div:\n",
    "                    letras.append(letra_div.get_text(strip=True))\n",
    "                else:\n",
    "                    letras.append(\"Letra no encontrada\")\n",
    "            else:\n",
    "                letras.append(\"Error al obtener letra\")\n",
    "\n",
    "    # Creamos un DataFrame con los resultados\n",
    "    df = pd.DataFrame({\n",
    "        'Titulo': titulos,\n",
    "        'Letra': letras\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Uso de la función\n",
    "artista = \"lasso\"\n",
    "df_canciones = descargar_letras(artista)\n",
    "\n",
    "# Verificar el DataFrame\n",
    "if df_canciones.empty:\n",
    "    print(\"El DataFrame está vacío. Verifica los elementos en la página.\")\n",
    "else:\n",
    "    print(df_canciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Letra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Titulo, Letra]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL de la página que queremos scrapear\n",
    "url_base = \"https://www.letras.com\"\n",
    "\n",
    "# Realizamos la solicitud GET para obtener el contenido de la página\n",
    "html_obtenido = requests.get(url_base)\n",
    "soup = BeautifulSoup(html_obtenido.text, \"html.parser\")\n",
    "\n",
    "# Inicializamos listas para los títulos y puntajes\n",
    "titulos = []\n",
    "letra = []\n",
    "\n",
    "# Buscamos todos los contenedores de mangas en la página\n",
    "manga_containers = soup.find_all('h3', class_='Más reproducidas')\n",
    "\n",
    "for container in manga_containers:\n",
    "    # Extraemos el título de la canción\n",
    "    titulo_element = container.find('artistTopSongs  u-contentVisibility-auto')\n",
    "    if titulo_element:\n",
    "        titulos.append(titulo_element.text.strip('span'))\n",
    "\n",
    "    # Extraemos la letra de la canción\n",
    "    score_element = container.find('p')\n",
    "    if score_element:\n",
    "        letra.append(score_element.text.strip())\n",
    "        \n",
    "    #url_element = container.find('a')\n",
    "    #for i in manga_containers:\n",
    "     # print(i('href'))\n",
    "\n",
    "# Creamos un DataFrame con los resultados\n",
    "df = pd.DataFrame({\n",
    "    'Titulo': titulos,\n",
    "    'Letra': letra\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Letra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Titulo, Letra]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL de la página que queremos scrapear\n",
    "url_base = \"https://www.letras.com\"\n",
    "\n",
    "# Realizamos la solicitud GET para obtener el contenido de la página\n",
    "html_obtenido = requests.get(url_base)\n",
    "soup = BeautifulSoup(html_obtenido.text, \"html.parser\")\n",
    "\n",
    "# Inicializamos listas para los títulos y puntajes\n",
    "titulos = []\n",
    "letra = []\n",
    "\n",
    "# Buscamos todos los contenedores de mangas en la página\n",
    "manga_containers = soup.find_all('<div', class_='artist-content gridContainer --flex')\n",
    "\n",
    "for container in manga_containers:\n",
    "    # Extraemos el título de la canción\n",
    "    titulo_element = container.find('a href')\n",
    "    if titulo_element:\n",
    "        titulos.append(titulo_element.text.strip('<span>'))\n",
    "\n",
    "    # Extraemos la letra de la canción\n",
    "    score_element = container.find('p')\n",
    "    if score_element:\n",
    "        letra.append(score_element.text.strip())\n",
    "        \n",
    "    #url_element = container.find('a')\n",
    "    #for i in manga_containers:\n",
    "     # print(i('href'))\n",
    "\n",
    "# Creamos un DataFrame con los resultados\n",
    "df = pd.DataFrame({\n",
    "    'Titulo': titulos,\n",
    "    'Letra': letra\n",
    "})\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "bootcamp-ds-NHz2zIBL-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
